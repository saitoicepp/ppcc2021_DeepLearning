{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みニューラルネットワーク (CNN) \n",
    "CNN は画像認識の分野で非常によく使われています。\n",
    "ここでは CNNをKerasで実装して、手書き文字認識(MNIST)の問題を解いてみます。\n",
    "\n",
    "https://www.tensorflow.org/tutorials/images/cnn?hl=ja をベースにしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflowが使うCPUの数を制限します。(VMを使う場合)\n",
    "%env OMP_NUM_THREADS=1\n",
    "%env TF_NUM_INTEROP_THREADS=1\n",
    "%env TF_NUM_INTRAOP_THREADS=1\n",
    "\n",
    "from tensorflow.config import threading\n",
    "num_threads = 1\n",
    "threading.set_inter_op_parallelism_threads(num_threads)\n",
    "threading.set_intra_op_parallelism_threads(num_threads)\n",
    "\n",
    "#ライブラリのインポート\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST データセットのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST データセットのインポート\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# ピクセルの値を 0~1 の間に正規化\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_`は学習用データセット、`test_`はモデル評価用データセットです。\n",
    "`_images` は 28 x 28 ピクセルの画像データです。\n",
    "`_labels` はその画像の数字のラベルが入っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 画像の表示\n",
    "画像と、それに対応するラベルを見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "plt.imshow(train_images[index])\n",
    "plt.show()\n",
    "print(f'label = {train_labels[index]}')\n",
    "\n",
    "index = 1\n",
    "plt.imshow(train_images[index])\n",
    "plt.show()\n",
    "print(f'label = {train_labels[index]}')\n",
    "\n",
    "index = 2\n",
    "plt.imshow(train_images[index])\n",
    "plt.show()\n",
    "print(f'label = {train_labels[index]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニング\n",
    "トレーニング用データは6万画像ありますが、ここでは計算時間を短くするため、6000画像だけ使ってトレーニングしてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "num_images = 6000\n",
    "model.fit(\n",
    "    x=train_images[:num_images],\n",
    "    y=train_labels[:num_images],\n",
    "    batch_size=100,\n",
    "    validation_split=0.2,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能評価\n",
    "性能評価用のデータセット(`test`)を使って性能評価してみましょう。\n",
    "`evaluate`関数を使うことで、モデルのメトリックが評価できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの性能評価\n",
    "model.evaluate(\n",
    "    x=test_images,\n",
    "    y=test_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[]の中の1つ目が誤差関数の値、2つめがaccuracy (正答率)です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy が 95%以上と、良い精度で判別ができていると思います。\n",
    "間違った画像がどのようなものかも確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_images)\n",
    "pred_labels = np.argmax(prediction, axis=1)\n",
    "print(f'wrong image index: {np.where(test_labels != pred_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1  # 上で得られた誤った予測のindexを入れてください。 (例: 42)\n",
    "plt.imshow(test_images[index])\n",
    "plt.show()\n",
    "print(f'label = {test_labels[index]}')\n",
    "print(f'prediction = {pred_labels[index]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNとMLPの比較\n",
    "MNIST を MLPで解くとどうなるかも調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Reshape, Dense\n",
    "\n",
    "# モデルの定義\n",
    "model_dnn = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),  # 画像を1次元のベクトルに変換\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_dnn.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model_dnn.summary()\n",
    "\n",
    "num_images = 6000\n",
    "model_dnn.fit(\n",
    "    x=train_images[:num_images],\n",
    "    y=train_labels[:num_images],\n",
    "    batch_size=100,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# モデルの性能評価\n",
    "model_dnn.evaluate(\n",
    "    x=test_images,\n",
    "    y=test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どのくらいの精度が出たでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次は、画像のピクセルのシャッフルをしてみます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全ての画像に対して、同じルールでピクセルのシャッフルをしています。\n",
    "permute = np.random.permutation(28 * 28)\n",
    "train_images_shuffle = train_images.reshape([-1, 28 * 28, 1])[:, permute, :].reshape([-1, 28, 28, 1])\n",
    "test_images_shuffle = test_images.reshape([-1, 28 * 28, 1])[:, permute, :].reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを画像としてプロットすると、人間には理解不能なものになっていることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images_shuffle[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これをCNN, MLPで学習させると、どうなるでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN の学習\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model_cnn = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_cnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "num_images = 6000\n",
    "model_cnn.fit(\n",
    "    x=train_images_shuffle[:num_images],\n",
    "    y=train_labels[:num_images],\n",
    "    batch_size=100,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# モデルの性能評価\n",
    "model_cnn.evaluate(\n",
    "    x=test_images_shuffle,\n",
    "    y=test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN の学習\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Reshape, Dense\n",
    "\n",
    "# モデルの定義\n",
    "model_dnn = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),  # 画像を1次元のベクトルに変換\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(128, activation='relu'),  # ノード数が128の層を追加。活性化関数はReLU。\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model_dnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "num_images = 6000\n",
    "model_dnn.fit(\n",
    "    x=train_images_shuffle[:num_images],\n",
    "    y=train_labels[:num_images],\n",
    "    batch_size=100,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# モデルの性能評価\n",
    "model_dnn.evaluate(\n",
    "    x=test_images_shuffle,\n",
    "    y=test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像のピクセルをシャッフルする前と比べて、CNN/DNNの性能はどのように変化したでしょうか？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5ee84ca7cc839add57a1456079373a6ef1d5daac4f4be388eaa02049720b4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
