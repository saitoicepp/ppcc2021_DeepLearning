{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs Challenge\n",
    "2014年に行われたコンテストを題材に、深層学習を実践してみましょう。\n",
    "\n",
    "以下は関連するwebページです。適宜参照してください。\n",
    "* Kaggleのページ: https://www.kaggle.com/c/higgs-boson\n",
    "* コンテスト結果のサマリーペーパー: http://proceedings.mlr.press/v42/cowa14.pdf\n",
    "* Datasetの説明ページ: http://opendata.cern.ch/record/328\n",
    "* Starting Kit: https://higgsml.lal.in2p3.fr/software/starting-kit/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflowが使うCPUの数を制限します。(VMを使う場合)\n",
    "%env OMP_NUM_THREADS=1\n",
    "%env TF_NUM_INTEROP_THREADS=1\n",
    "%env TF_NUM_INTRAOP_THREADS=1\n",
    "\n",
    "from tensorflow.config import threading\n",
    "num_threads = 1\n",
    "threading.set_inter_op_parallelism_threads(num_threads)\n",
    "threading.set_intra_op_parallelism_threads(num_threads)\n",
    "\n",
    "#ライブラリのインポート\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットのダウンロード・読み込み\n",
    "提供しているバーチャルマシンを使用している場合は`/data/staff/deeplearning`にデータセットがおいてあるので、これを使ってください。\n",
    "\n",
    "その他の環境を使用している場合は各自データをダウンロード・解凍をしてください。\n",
    "```bash\n",
    "$ wget http://opendata.cern.ch/record/328/files/atlas-higgs-challenge-2014-v2.csv.gz\n",
    "$ gunzip atlas-higgs-challenge-2014-v2.csv.gz\n",
    "```\n",
    "\n",
    "CSVデータの読み込み・処理には、今回はpandasというライブラリを使ってみます。\n",
    "`read_csv`の引数は、CSVデータがある場所に適宜書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvファイルの読み込み\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/data/staff/deeplearning/atlas-higgs-challenge-2014-v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://opendata.cern.ch/record/328 で説明されているように、多くの変数が定義されています。それぞれの変数の定義は各自確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数の各種統計量の表示\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使う変数の選別\n",
    "いろいろな変数がありますが、ここでは使用できる全ての変数を使ってみることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全ての変数を使う例\n",
    "X = df[[\n",
    "    'DER_mass_MMC',\n",
    "    'DER_mass_transverse_met_lep',\n",
    "    'DER_mass_vis',\n",
    "    'DER_pt_h',\n",
    "    'DER_deltaeta_jet_jet',\n",
    "    'DER_mass_jet_jet',\n",
    "    'DER_prodeta_jet_jet',\n",
    "    'DER_deltar_tau_lep',\n",
    "    'DER_pt_tot',\n",
    "    'DER_sum_pt',\n",
    "    'DER_pt_ratio_lep_tau',\n",
    "    'DER_met_phi_centrality',\n",
    "    'DER_lep_eta_centrality',\n",
    "    'PRI_tau_pt',\n",
    "    'PRI_tau_eta',\n",
    "    'PRI_tau_phi',\n",
    "    'PRI_lep_pt',\n",
    "    'PRI_lep_eta',\n",
    "    'PRI_lep_phi',\n",
    "    'PRI_met',\n",
    "    'PRI_met_phi',\n",
    "    'PRI_met_sumet',\n",
    "    'PRI_jet_num',\n",
    "    'PRI_jet_leading_pt',\n",
    "    'PRI_jet_leading_eta',\n",
    "    'PRI_jet_leading_phi',\n",
    "    'PRI_jet_subleading_pt',\n",
    "    'PRI_jet_subleading_eta',\n",
    "    'PRI_jet_subleading_phi',\n",
    "    'PRI_jet_all_pt'\n",
    "]]\n",
    "\n",
    "# 一部だけの変数を使う例\n",
    "# X = df[['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目標変数とweightの指定\n",
    "Y = df['Label']\n",
    "W = df['KaggleWeight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label はそのイベントがシグナル、すなわち$H\\rightarrow \\tau\\tau $事象か、バックグラウンドかを表すラベルです。(シグナルは`s`, バックグラウンドは`b`)\n",
    "\n",
    "KaggleWeightはKaggleでのコンテストで使われたイベントウェイトです。この値が大きいほど、重要なイベントだと思ってください。モデルの評価時には、このweightを使って性能評価をします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理(Preprocessing)\n",
    "必要に応じて、前処理を行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -999 が入っているところを 0 に変換\n",
    "X = X.replace(-999., 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "扱いやすように、それぞれの変数をnumpy形式に変換しておきます。\n",
    "\n",
    "また、ラベルの`s`,`b`,を数値(`s`=1, `b`=0)に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X を numpy.array 形式に変換します。\n",
    "X = X.values\n",
    "\n",
    "# Y を s/b から 1/0に変換します。\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Y = LabelEncoder().fit_transform(Y)\n",
    "\n",
    "# W を numpy.array 形式に変換します。\n",
    "W = W.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの分割\n",
    "\n",
    "トレーニング用データセットと評価用データセットに分けます。\n",
    "\n",
    "トレーニングには、`KaggleSet`の値が`t`(training)のものを使ってください。\n",
    "モデルの評価には、`KaggleSet`の値が`v`(private leaderboard)のものを使ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[df['KaggleSet'] == 't']\n",
    "Y_train = Y[df['KaggleSet'] == 't']\n",
    "W_train = W[df['KaggleSet'] == 't']\n",
    "\n",
    "X_test = X[df['KaggleSet'] == 'v']\n",
    "Y_test = Y[df['KaggleSet'] == 'v']\n",
    "W_test = W[df['KaggleSet'] == 'v']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深層学習モデルの作成とトレーニング\n",
    "\n",
    "適当なニューラルネットワークを作成、学習させてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN の学習\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Reshape, Dense\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=X.shape[1:]),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    batch_size=1000,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価指標の計算\n",
    "\n",
    "このコンテストでは、AMS(approximate median significance)という指標が使われました。AMSは以下のように定義されています。\n",
    "$$\n",
    "\\text{AMS} = \\sqrt{2 \\left( ( s + b + 10 ) \\log \\left( 1 + \\frac{s}{b + 10} \\right) - s \\right)}\n",
    "$$\n",
    "(詳細はhttp://opendata.cern.ch/record/328 を参照してください。)\n",
    "ここで、`s`はシグナルの数、`b`はバックグラウンドの数です。\n",
    "\n",
    "この指標を最大にするようなモデルを作成してください。\n",
    "\n",
    "この指標を計算する関数を以下に用意しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ams(s, b):\n",
    "    import math\n",
    "    br = 10.0\n",
    "    return math.sqrt(2 * ( (s + b + br) * math.log(1.0 + s / (b + br)) - s ))\n",
    "\n",
    "def ams(y_true, y_pred, w, thr):\n",
    "    # yのshapeを1次元にします。(例: (100, 1) -> (100,))\n",
    "    y_true = y_true.ravel()\n",
    "    y_pred = y_pred.ravel()\n",
    "\n",
    "    # NN output が thr 以上(selectionをpassした)イベントの内、真のラベルが1(シグナル)のもの\n",
    "    s = w[np.logical_and(y_true == 1, y_pred >= thr)].sum()\n",
    "    # NN output が thr 以上(selectionをpassした)イベントの内、真のラベルが0(バックグラウンド)のもの\n",
    "    b = w[np.logical_and(y_true == 0, y_pred >= thr)].sum()\n",
    "\n",
    "    return _ams(s, b)\n",
    "\n",
    "def get_best_thr(y_true, y_pred, w):\n",
    "    import numpy as np\n",
    "    thresholds = np.linspace(0, 1, 1000)\n",
    "    ams_l = [ams(y_true, y_pred, w, thr) for thr in thresholds]\n",
    "\n",
    "    # 閾値をスキャンさせた中で、最もAMSが高かったものを返します。 \n",
    "    bestIndex = ams_l.index(max(ams_l))\n",
    "    return thresholds[bestIndex]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上でトレーニングしたモデルでAMSを計算してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングサンプルを使ってNN outputに対する最適な閾値を計算します。\n",
    "Y_pred = model.predict(X_train)\n",
    "thr = get_best_thr(Y_train, Y_pred, W_train)\n",
    "print(f\"thr = {thr}\")\n",
    "\n",
    "# 評価用サンプルで AMS を計算します。\n",
    "Y_pred = model.predict(X_test)\n",
    "print(f\"AMS (test) = {ams(Y_test, Y_pred, W_test, thr)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コンテストでは、一位の人のスコアは 3.8 でした。\n",
    "これを超えることはできるでしょうか？\n",
    "\n",
    "ぜひいろいろ試してみてください。その際、操作の意味を考えて試行錯誤することを推奨します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoreの参考値\n",
    "- 1st place: 3.80581\n",
    "- MultiBoost: 3.40487\n",
    "- simple TMVA boosted trees: 3.19956\n",
    "- Naive Bayes starting kit: 2.06020\n",
    "- Simple window: 1.53518\n",
    "- Random submission: 0.58647"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5ee84ca7cc839add57a1456079373a6ef1d5daac4f4be388eaa02049720b4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
