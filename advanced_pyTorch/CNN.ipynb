{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みニューラルネットワーク (CNN) \n",
    "CNN は画像認識の分野で非常によく使われています。\n",
    "ここでは CNNをPyTorchで実装して、手書き文字認識(MNIST)の問題を解いてみます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorchが使うCPUの数を制限します。(VMを使う場合)\n",
    "%env OMP_NUM_THREADS=1\n",
    "%env MKL_NUM_THREADS=1\n",
    "\n",
    "from torch import set_num_threads, set_num_interop_threads\n",
    "num_threads = 1\n",
    "set_num_threads(num_threads)\n",
    "set_num_interop_threads(num_threads)\n",
    "\n",
    "#ライブラリのインポート\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST データセットのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST データセットのインポート\n",
    "from torchvision import datasets, transforms\n",
    "train_dataset = datasets.MNIST('/data/staff/deeplearning/datasets_pytorch', train=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST('/data/staff/deeplearning/datasets_pytorch', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_dataset`は学習用データセット、`test_dataset`はモデル評価用データセットです。\n",
    "それぞれのデータセットのエントリーは以下のようにして確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_0th, label_0th = train_dataset[0]\n",
    "print('image shape = ', image_0th.shape)\n",
    "print('label = ', label_0th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ミニバッチの実装を簡単にするため、DataLoaderを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoaderを使うと、以下のように指定したバッチサイズでデータが簡単に取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dataloader:\n",
    "    # for文で指定したバッチサイズ(ここでは100)ごとにデータが切り出されます。\n",
    "    print(f'image shape = {images.shape}, labels shape = {labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNISTのトレーニング用データは6万画像ありますが、このノートブック内では計算時間を短くするため、6000画像だけを使うことにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "train_dataloader = DataLoader(Subset(train_dataset, np.arange(6000)), batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 画像の表示\n",
    "画像と、それに対応するラベルを見てみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "plt.imshow(train_dataset[index][0].squeeze())\n",
    "plt.show()\n",
    "print(f'label = {train_dataset[index][1]}')\n",
    "\n",
    "index = 1\n",
    "plt.imshow(train_dataset[index][0].squeeze())\n",
    "plt.show()\n",
    "print(f'label = {train_dataset[index][1]}')\n",
    "\n",
    "index = 2\n",
    "plt.imshow(train_dataset[index][0].squeeze())\n",
    "plt.show()\n",
    "print(f'label = {train_dataset[index][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "\n",
    "model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n",
    "    MaxPool2d(kernel_size=(2, 2)),\n",
    "    Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n",
    "    MaxPool2d(kernel_size=(2, 2)),\n",
    "    Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3)),\n",
    "    Flatten(),\n",
    "    Linear(in_features=576, out_features=64),\n",
    "    ReLU(),\n",
    "    Linear(in_features=64, out_features=10),\n",
    "    # Softmax(dim=1)  # PyTorchではロス関数に CrossEntropyLoss を指定すると、自動でSoftmaxが適用されます。そのため、モデルにSoftmaxを適用する必要はありません。\n",
    ")\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(\n",
    "    model,\n",
    "    input_size=next(iter(train_dataloader))[0].shape,\n",
    "    col_names=['output_size', 'num_params']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "# トレーニング\n",
    "num_epochs = 10\n",
    "for i_epoch in range(num_epochs):\n",
    "\n",
    "    # エポックごとのロス、accuracyを計算するための変数\n",
    "    loss_total = 0.\n",
    "    accuracy_total = 0.\n",
    "\n",
    "    for images, labels in train_dataloader:\n",
    "        model.train()\n",
    "\n",
    "        # 順伝搬\n",
    "        y_pred = model(images)\n",
    "\n",
    "        # ロスの計算\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        loss_total += loss.detach().numpy()\n",
    "\n",
    "        # 誤差逆伝播の前に各パラメータの勾配の値を0にセットする。\n",
    "        # これをしないと、勾配の値はそれまでの値との和がとられる。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 誤差逆伝播。各パラメータの勾配が計算される。\n",
    "        loss.backward()\n",
    "\n",
    "        # 各パラメータの勾配の値を基に、optimizerにより値が更新される。\n",
    "        optimizer.step()\n",
    "\n",
    "        # 正解率(Accuracy)\n",
    "        label_pred = y_pred.max(dim=1)[1]\n",
    "        accuracy_total += (label_pred == labels).sum().numpy() / len(images)\n",
    "    \n",
    "    # ロス、accuracyをミニバッチの数で割って平均を取ります。\n",
    "    loss_total /= len(train_dataloader)\n",
    "    accuracy_total /= len(train_dataloader)\n",
    "    print(f'epoch = {i_epoch}, loss = {loss_total}, acc = {accuracy_total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能評価\n",
    "性能評価用のデータセット(`test_dataloader`)を使って性能評価してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの性能評価\n",
    "loss_total = 0\n",
    "accuracy_total = 0.\n",
    "\n",
    "model.eval()\n",
    "for images, labels in test_dataloader:\n",
    "    # 順伝搬\n",
    "    y_pred = model(images)\n",
    "\n",
    "    # ロスの計算\n",
    "    loss = loss_fn(y_pred, labels)\n",
    "    loss_total += loss.detach().numpy()\n",
    "\n",
    "    # 正解率(Accuracy)の計算\n",
    "    label_pred = y_pred.max(dim=1)[1]\n",
    "    accuracy_total += (label_pred == labels).sum().numpy() / len(images)\n",
    "\n",
    "loss_total /= len(test_dataloader)\n",
    "accuracy_total /= len(test_dataloader)\n",
    "print(f'loss = {loss_total}, acc = {accuracy_total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy が 95%以上と、良い精度で判別ができていると思います。\n",
    "間違った画像がどのようなものかも確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "import torch\n",
    "for images, labels in test_dataloader:\n",
    "    y_pred = model(images)\n",
    "    label_pred = y_pred.max(dim=1)[1]\n",
    "\n",
    "    # 予測値と正解ラベルが一致していないエントリーを抽出します。\n",
    "    wrong_image_indices = (label_pred != labels).nonzero().numpy()\n",
    "\n",
    "    for index in wrong_image_indices:\n",
    "        plt.imshow(images[index].squeeze())\n",
    "        plt.show()\n",
    "        print(f'label = {labels[index].squeeze().numpy()}')\n",
    "        print(f'prediction = {label_pred[index].squeeze().numpy()}')\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (おまけ) CNNとMLPの比較\n",
    "MNIST を MLPで解くとどうなるかも調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "# モデルの定義\n",
    "model_dnn = Sequential(\n",
    "    Flatten(),  # 画像を1次元のベクトルに変換: 28 * 28 = 784\n",
    "    Linear(in_features=784, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=10),  # ノード数が10の層を追加。\n",
    ")\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = Adam(model_dnn.parameters())\n",
    "\n",
    "# トレーニング\n",
    "num_epochs = 10\n",
    "for i_epoch in range(num_epochs):\n",
    "    loss_total = 0.\n",
    "    accuracy_total = 0.\n",
    "    for images, labels in train_dataloader:\n",
    "        model_dnn.train()\n",
    "\n",
    "        # 順伝搬\n",
    "        y_pred = model_dnn(images)\n",
    "\n",
    "        # ロスの計算\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        loss_total += loss.detach().numpy()\n",
    "\n",
    "        # 誤差逆伝播の前に各パラメータの勾配の値を0にセットする。\n",
    "        # これをしないと、勾配の値はそれまでの値との和がとられる。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 誤差逆伝播。各パラメータの勾配が計算される。\n",
    "        loss.backward()\n",
    "\n",
    "        # 各パラメータの勾配の値を基に、optimizerにより値が更新される。\n",
    "        optimizer.step()\n",
    "\n",
    "        # 正解率(Accuracy)\n",
    "        label_pred = y_pred.max(dim=1)[1]\n",
    "        accuracy_total += (label_pred == labels).sum().numpy() / len(images)\n",
    "    \n",
    "    # ロス、accuracyをミニバッチの数で割って平均を取ります。\n",
    "    loss_total /= len(train_dataloader)\n",
    "    accuracy_total /= len(train_dataloader)\n",
    "    print(f'epoch = {i_epoch}, loss = {loss_total}, acc = {accuracy_total}')\n",
    "\n",
    "# モデルの性能評価\n",
    "loss_total = 0\n",
    "accuracy_total = 0.\n",
    "\n",
    "model_dnn.eval()\n",
    "for images, labels in test_dataloader:\n",
    "    # 順伝搬\n",
    "    y_pred = model_dnn(images)\n",
    "\n",
    "    # ロスの計算\n",
    "    loss = loss_fn(y_pred, labels)\n",
    "    loss_total += loss.detach().numpy()\n",
    "\n",
    "    # 正解率(Accuracy)の計算\n",
    "    label_pred = y_pred.max(dim=1)[1]\n",
    "    accuracy_total += (label_pred == labels).sum().numpy() / len(images)\n",
    "\n",
    "loss_total /= len(test_dataloader)\n",
    "accuracy_total /= len(test_dataloader)\n",
    "print(f'test loss = {loss_total}, test acc = {accuracy_total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どのくらいの精度が出たでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次は、画像のピクセルのシャッフルをしてみます。\n",
    "\n",
    "これを画像としてプロットすると、人間には理解不能なものになっていることがわかります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_dataset[0][0]\n",
    "\n",
    "# 全ての画像に対して、同じルールでピクセルのシャッフルをします。\n",
    "permute = np.random.permutation(28 * 28)\n",
    "image = image.numpy().flatten()[permute].reshape([1, 28, 28])\n",
    "\n",
    "plt.imshow(image.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これをCNN, MLPで学習させると、どうなるでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN の学習\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "model_cnn = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)),\n",
    "    MaxPool2d(kernel_size=(2, 2)),\n",
    "    Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)),\n",
    "    MaxPool2d(kernel_size=(2, 2)),\n",
    "    Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3)),\n",
    "    Flatten(),\n",
    "    Linear(in_features=576, out_features=64),\n",
    "    ReLU(),\n",
    "    Linear(in_features=64, out_features=10),\n",
    ")\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = Adam(model_cnn.parameters())\n",
    "\n",
    "# トレーニング\n",
    "num_epochs = 10\n",
    "for i_epoch in range(num_epochs):\n",
    "    loss_total = 0.\n",
    "    accuracy_total = 0.\n",
    "    for images, labels in train_dataloader:\n",
    "        model_cnn.train()\n",
    "\n",
    "        # 全ての画像に対して、同じルールでピクセルのシャッフルをします。\n",
    "        images = images.flatten(start_dim=2)[:, :, permute].reshape([-1, 1, 28, 28])\n",
    "\n",
    "        # 順伝搬\n",
    "        y_pred = model_cnn(images)\n",
    "\n",
    "        # ロスの計算\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        loss_total += loss.detach().numpy()\n",
    "\n",
    "        # 誤差逆伝播の前に各パラメータの勾配の値を0にセットする。\n",
    "        # これをしないと、勾配の値はそれまでの値との和がとられる。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 誤差逆伝播。各パラメータの勾配が計算される。\n",
    "        loss.backward()\n",
    "\n",
    "        # 各パラメータの勾配の値を基に、optimizerにより値が更新される。\n",
    "        optimizer.step()\n",
    "\n",
    "        # 正解率(Accuracy)\n",
    "        label_pred = y_pred.max(dim=1)[1]\n",
    "        accuracy_total += (label_pred == labels).sum().numpy() / len(images)\n",
    "    \n",
    "    # ロス、accuracyをミニバッチの数で割って平均を取ります。\n",
    "    loss_total /= len(train_dataloader)\n",
    "    accuracy_total /= len(train_dataloader)\n",
    "    print(f'epoch = {i_epoch}, loss = {loss_total}, acc = {accuracy_total}')\n",
    "\n",
    "\n",
    "# モデルの性能評価\n",
    "loss_total = 0\n",
    "accuracy_total = 0.\n",
    "\n",
    "model_cnn.eval()\n",
    "for images, labels in test_dataloader:\n",
    "    # 全ての画像に対して、同じルールでピクセルのシャッフルをします。\n",
    "    images = images.flatten(start_dim=2)[:, :, permute].reshape([-1, 1, 28, 28])\n",
    "\n",
    "    # 順伝搬\n",
    "    y_pred = model_cnn(images)\n",
    "\n",
    "    # ロスの計算\n",
    "    loss = loss_fn(y_pred, labels)\n",
    "    loss_total += loss.detach().numpy()\n",
    "\n",
    "    # 正解率(Accuracy)の計算\n",
    "    label_pred = y_pred.max(dim=1)[1]\n",
    "    accuracy_total += (label_pred == labels).sum().numpy() / len(images)\n",
    "\n",
    "loss_total /= len(test_dataloader)\n",
    "accuracy_total /= len(test_dataloader)\n",
    "print(f'test loss = {loss_total}, test acc = {accuracy_total}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "# モデルの定義\n",
    "model_dnn = Sequential(\n",
    "    Flatten(),  # 画像を1次元のベクトルに変換: 28 * 28 = 784\n",
    "    Linear(in_features=784, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=128),  # ノード数が128の層を追加。\n",
    "    ReLU(),  # 活性化関数はReLU。\n",
    "    Linear(in_features=128, out_features=10),  # ノード数が10の層を追加。\n",
    ")\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = Adam(model_dnn.parameters())\n",
    "\n",
    "# トレーニング\n",
    "num_epochs = 10\n",
    "for i_epoch in range(num_epochs):\n",
    "    loss_total = 0.\n",
    "    accuracy_total = 0.\n",
    "    for images, labels in train_dataloader:\n",
    "        model_dnn.train()\n",
    "\n",
    "        # 全ての画像に対して、同じルールでピクセルのシャッフルをします。\n",
    "        images = images.flatten(start_dim=2)[:, :, permute].reshape([-1, 1, 28, 28])\n",
    "\n",
    "        # 順伝搬\n",
    "        y_pred = model_dnn(images)\n",
    "\n",
    "        # ロスの計算\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        loss_total += loss.detach().numpy()\n",
    "\n",
    "        # 誤差逆伝播の前に各パラメータの勾配の値を0にセットする。\n",
    "        # これをしないと、勾配の値はそれまでの値との和がとられる。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 誤差逆伝播。各パラメータの勾配が計算される。\n",
    "        loss.backward()\n",
    "\n",
    "        # 各パラメータの勾配の値を基に、optimizerにより値が更新される。\n",
    "        optimizer.step()\n",
    "\n",
    "        # 正解率(Accuracy)\n",
    "        label_pred = y_pred.max(dim=1)[1]\n",
    "        accuracy_total += (label_pred == labels).sum().numpy() / len(images)\n",
    "    \n",
    "    # ロス、accuracyをミニバッチの数で割って平均を取ります。\n",
    "    loss_total /= len(train_dataloader)\n",
    "    accuracy_total /= len(train_dataloader)\n",
    "    print(f'epoch = {i_epoch}, loss = {loss_total}, acc = {accuracy_total}')\n",
    "\n",
    "# モデルの性能評価\n",
    "loss_total = 0\n",
    "accuracy_total = 0.\n",
    "\n",
    "model_dnn.eval()\n",
    "for images, labels in test_dataloader:\n",
    "    # 全ての画像に対して、同じルールでピクセルのシャッフルをします。\n",
    "    images = images.flatten(start_dim=2)[:, :, permute].reshape([-1, 1, 28, 28])\n",
    "\n",
    "    # 順伝搬\n",
    "    y_pred = model_dnn(images)\n",
    "\n",
    "    # ロスの計算\n",
    "    loss = loss_fn(y_pred, labels)\n",
    "    loss_total += loss.detach().numpy()\n",
    "\n",
    "    # 正解率(Accuracy)の計算\n",
    "    label_pred = y_pred.max(dim=1)[1]\n",
    "    accuracy_total += (label_pred == labels).sum().numpy() / len(images)\n",
    "\n",
    "loss_total /= len(test_dataloader)\n",
    "accuracy_total /= len(test_dataloader)\n",
    "print(f'test loss = {loss_total}, test acc = {accuracy_total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像のピクセルをシャッフルする前と比べて、CNN/DNNの性能はどのように変化したでしょうか？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5ee84ca7cc839add57a1456079373a6ef1d5daac4f4be388eaa02049720b4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
