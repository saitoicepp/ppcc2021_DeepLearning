{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ライブラリのインポート\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUによる高速化\n",
    "\n",
    "TensorflowやPyTorchといった深層学習ライブラリはGPUでの実行がサポートされています。\n",
    "GPUを使うことで大規模計算が高速化できることがあります。\n",
    "\n",
    "このノートブックではTensorflow/KerasやPyTorchをGPU上で実行し、CPUでの実行したときと計算速度を比較します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPUの利用状況の確認\n",
    "\n",
    "現在接続しているノードのGPU使用率は`nvidia-smi`コマンドで確認できます。\n",
    "```bash\n",
    "$ nvidia-smi\n",
    "Fri Jul 28 17:22:22 2023       \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA A100-SXM4-40GB           Off| 00000000:13:00.0 Off |                   On |\n",
    "| N/A   24C    P0               51W / 400W|    877MiB / 40960MiB |     N/A      Default |\n",
    "|                                         |                      |              Enabled |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| MIG devices:                                                                          |\n",
    "+------------------+--------------------------------+-----------+-----------------------+\n",
    "| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |\n",
    "|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG|\n",
    "|                  |                                |        ECC|                       |\n",
    "|==================+================================+===========+=======================|\n",
    "|  0    7   0   0  |              12MiB /  4864MiB  | 14      0 |  1   0    0    0    0 |\n",
    "|                  |               0MiB /  8191MiB  |           |                       |\n",
    "+------------------+--------------------------------+-----------+-----------------------+\n",
    "|  0    8   0   1  |              12MiB /  4864MiB  | 14      0 |  1   0    0    0    0 |\n",
    "|                  |               0MiB /  8191MiB  |           |                       |\n",
    "+------------------+--------------------------------+-----------+-----------------------+\n",
    "|  0    9   0   2  |             802MiB /  4864MiB  | 14      0 |  1   0    0    0    0 |\n",
    "|                  |               2MiB /  8191MiB  |           |                       |\n",
    "+------------------+--------------------------------+-----------+-----------------------+\n",
    "|  0   10   0   3  |              12MiB /  4864MiB  | 14      0 |  1   0    0    0    0 |\n",
    "|                  |               0MiB /  8191MiB  |           |                       |\n",
    "+------------------+--------------------------------+-----------+-----------------------+\n",
    "|  0   11   0   4  |              12MiB /  4864MiB  | 14      0 |  1   0    0    0    0 |\n",
    "|                  |               0MiB /  8191MiB  |           |                       |\n",
    "+------------------+--------------------------------+-----------+-----------------------+\n",
    "|  0   12   0   5  |              12MiB /  4864MiB  | 14      0 |  1   0    0    0    0 |\n",
    "|                  |               0MiB /  8191MiB  |           |                       |\n",
    "+------------------+--------------------------------+-----------+-----------------------+\n",
    "|  0   13   0   6  |              12MiB /  4864MiB  | 14      0 |  1   0    0    0    0 |\n",
    "|                  |               0MiB /  8191MiB  |           |                       |\n",
    "+------------------+--------------------------------+-----------+-----------------------+\n",
    "                                                                                         \n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "|    0    9    0      11117      C   .../local/venv/deeplearning/bin/python      782MiB |\n",
    "+---------------------------------------------------------------------------------------+\n",
    "```\n",
    "このノードではGPU1台が搭載されていますが、複数のユーザーで共有して使用できるようにGPUを7分割しています。\n",
    "１つ目のブロックから、NVIDIA A100というGPUが載っていて、メモリは40960MiB ということが読み取れます。\n",
    "2つ目のブロックでは7分割された各GPUの状態が表示されています。上から3つ目のデバイス(GIID=9, MIG Dev=2)ではGPUメモリが802MiB使用されています。\n",
    "最後のブロックは、GPUを使用しているプロセスが表示されています。GIID=9 のGPUを1つのプロセスが使用していることが読み取れます。\n",
    "\n",
    "自分のプロセスがゾンビ状態となってGPUのメモリを専有してしまうことがないように定期的にチェックしてください。\n",
    "\n",
    "GPUを使っているプロセスを起動したユーザーを確認するコマンドの一例は以下です。\n",
    "```bash\n",
    "$ ps -up `nvidia-smi --query-compute-apps=pid --format=csv,noheader | sort -u`\n",
    "USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
    "```\n",
    "ここで表示されるメモリの値はGPU上のメモリではないことに注意してください。\n",
    "\n",
    "notebook上では\"!\"をつけることでbashコマンドが実行できます。     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用するGPUの指定\n",
    "まずは使うGPUを指定します。このステップなしでもGPUは利用できますが、GPUを専有してしまうことで共有マシンを使用している他のユーザーに迷惑をかけてしまうことがあります。\n",
    "今回の講習では、使うGPUは1つのみに限定させます。\n",
    "\n",
    "GPUを指定するには、TensorflowやPyTorchをimportする前に環境変数`CUDA_VISIBLE_DEVICES`にGPUのUUIDをしてしてください。\n",
    "```python\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = 'MIG-554c4086-6ae7-5b25-8c39-e5980d23ae92'\n",
    "```\n",
    "UUIDは以下のようにして確認することができます。\n",
    "```bash\n",
    "[saito@centos7 ~]$ nvidia-smi -L\n",
    "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-07ce7acc-c626-f86c-3b8c-170a84e404b3)\n",
    "  MIG 1g.5gb      Device  0: (UUID: MIG-554c4086-6ae7-5b25-8c39-e5980d23ae92)\n",
    "  MIG 1g.5gb      Device  1: (UUID: MIG-9b9d3d09-b7d8-5351-af1e-5607f0fbd02a)\n",
    "  MIG 1g.5gb      Device  2: (UUID: MIG-0dfbf33f-6966-5b43-a167-2cb7be339805)\n",
    "  MIG 1g.5gb      Device  3: (UUID: MIG-1baae807-2fcd-5438-8a89-d320680ade08)\n",
    "  MIG 1g.5gb      Device  4: (UUID: MIG-cedbde95-8c79-51e0-b848-7bf73342a233)\n",
    "  MIG 1g.5gb      Device  5: (UUID: MIG-84f9461f-49b6-5343-a3b9-5be94986cdad)\n",
    "  MIG 1g.5gb      Device  6: (UUID: MIG-95045bde-aa51-5831-8983-63dbf0262e77)\n",
    "```\n",
    "Device ID(上の例だと0 ~ 6)と`nvidia-smi`の出力を見比べて、使用されて**いない**GPUを選択するようにしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使うGPUを一つに制限します。\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = 'MIG-554c4086-6ae7-5b25-8c39-e5980d23ae92'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow でのGPU利用の注意点\n",
    "\n",
    "TensorflowはデフォルトでGPU上のメモリを全て確保しようとします。GPUを利用するのが1人だけの場合はこれで良いのですが、複数人で共有する場合は他のユーザーのプロセスを停止させてしまうこともあります。\n",
    "そのため、Tensorflowが必要な分だけGPUメモリを確保するように設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Tensorflowが使うCPUの数を制限します。(VMを使う場合)\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = '1'\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = '1'\n",
    "\n",
    "from tensorflow.config import threading\n",
    "num_threads = 1\n",
    "threading.set_inter_op_parallelism_threads(num_threads)\n",
    "threading.set_intra_op_parallelism_threads(num_threads)\n",
    "\n",
    "# GPUのメモリを使いすぎないように制限します。\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.set_visible_devices(physical_devices, 'GPU')\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print('available GPU:', logical_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPのトレーニング\n",
    "\n",
    "MLPのトレーニングをCPU/GPUでそれぞれ実行することで、計算時間の変化を確認します。\n",
    "\n",
    "データセットは乱数で適当に作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng(seed=0)\n",
    "\n",
    "# 100万行、入力次元100のランダムなデータを作成。\n",
    "datasize = 1000000\n",
    "x = rng.normal(size=(datasize, 100))\n",
    "t = rng.integers(0, 2, size=(datasize, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPUによるサンプルコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUがあるとGPUが自動で使われてしまいます。CPUで計算するように明示的に指定することでCPUで計算させることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    # モデルの定義\n",
    "    model = Sequential([\n",
    "        Dense(units=256, activation='relu', input_dim=100),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "        Dense(units=256, activation='relu'),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "        Dense(units=256, activation='relu'),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "        Dense(units=256, activation='relu'),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "        Dense(units=256, activation='relu'),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "        Dense(units=1, activation='sigmoid')  # ノード数が1の層を追加。活性化関数はシグモイド関数。\n",
    "    ])\n",
    "\n",
    "    #  誤差関数としてクロスエントロピーを指定。最適化手法はadam\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "    #  トレーニング\n",
    "    model.fit(\n",
    "        x=x,\n",
    "        y=t,\n",
    "        batch_size=1024,  # バッチサイズ。一回のステップで1024行のデータを使うようにする。\n",
    "        epochs=5,  # 学習のステップ数\n",
    "        verbose=1,  # 1とするとステップ毎に誤差関数の値などが表示される\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUによるサンプルコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential([\n",
    "    Dense(units=256, activation='relu', input_dim=100),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "    Dense(units=256, activation='relu'),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "    Dense(units=256, activation='relu'),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "    Dense(units=256, activation='relu'),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "    Dense(units=256, activation='relu'),  # ノード数が256の層を追加。活性化関数はReLU。\n",
    "    Dense(units=1, activation='sigmoid')  # ノード数が1の層を追加。活性化関数はシグモイド関数。\n",
    "])\n",
    "\n",
    "#  誤差関数としてクロスエントロピーを指定。最適化手法はadam\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "#  トレーニング\n",
    "model.fit(\n",
    "    x=x,\n",
    "    y=t,\n",
    "    batch_size=1024,  # バッチサイズ。一回のステップで1024行のデータを使うようにする。\n",
    "    epochs=5,  # 学習のステップ数\n",
    "    verbose=1,  # 1とするとステップ毎に誤差関数の値などが表示される\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算時間はどのように変化したでしょうか。\n",
    "モデルサイズが変化すると、計算時間はどのように変わるでしょうか？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
